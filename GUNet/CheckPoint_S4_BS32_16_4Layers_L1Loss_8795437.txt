Thu Jun  5 02:45:58 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:01:00.0 Off |                    0 |
| N/A   32C    P0             58W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
o03c04
[DEBUG] CPU available to this job: 64
Running pretraining with configuration:
{'SHOULD_TRAIN': True, 'PATH_TO_DATA': '/home/hd/hd_hd/hd_uu312/Cubes32', 'SUBSET_NAME': None, 'BATCH_SIZE': 16, 'NUM_WORKERS': 32, 'SEED': 1, 'GROUP': 'T4', 'GROUP_DIM': 12, 'IN_CHANNELS': 1, 'OUT_CHANNELS': 1, 'FINAL_ACTIVATION': None, 'NONLIN': 'leaky-relu', 'NORMALIZATION': 'bn', 'DIVIDER': 4, 'MODEL_DEPTH': 5, 'DROPOUT': 0.0, 'LOGS_DIR': '/home/hd/hd_hd/hd_uu312/CUNet/TensorBoard', 'LOG_NAME': 'T4_BS16_16_5Layers_L1Loss', 'LEARNING_RATE': 0.0001, 'GPUS': 1, 'PRECISION': 16, 'MAX_EPOCHS': 10, 'VAL_CHECK_INTERVAL': 0.1, 'LOG_EVERY_N_STEPS': 100, 'PROGRESS_BAR_REFRESH_RATE': 50, 'LR_PATIENCE': 10, 'LR_FACTOR': 0.7, 'LR_MIN': 1e-06}
[INFO] Total subjects: 109368
[INFO] Train set: 87495
[INFO] Val set: 21873
Training started at 2025-06-05 02:57:38.355696
/home/hd/hd_hd/hd_uu312/miniconda3/envs/CUNet/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:360: UserWarning: Checkpoint directory /home/hd/hd_hd/hd_uu312/CUNet/TensorBoard/T4_BS16_16_5Layers_L1Loss/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
/home/hd/hd_hd/hd_uu312/miniconda3/envs/CUNet/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:338: UserWarning: ModelCheckpoint(save_last=True, save_top_k=None, monitor=None) is a redundant configuration. You can save the last checkpoint with ModelCheckpoint(save_top_k=None, monitor=None).
  rank_zero_warn(
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]                                                              [DEBUG] Expected training steps per epoch: 87495
/home/hd/hd_hd/hd_uu312/miniconda3/envs/CUNet/lib/python3.8/site-packages/torch/nn/functional.py:4043: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/hd/hd_hd/hd_uu312/miniconda3/envs/CUNet/lib/python3.8/site-packages/torch/nn/functional.py:3981: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/19138 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/19138 [00:00<?, ?it/s] Epoch 0:   0%|          | 50/19138 [06:02<38:26:11,  7.25s/it]Epoch 0:   0%|          | 50/19138 [06:02<38:26:12,  7.25s/it, loss=0.549, v_num=1, val_loss=0.803, train_loss=0.533]Epoch 0:   1%|          | 100/19138 [11:17<35:48:59,  6.77s/it, loss=0.549, v_num=1, val_loss=0.803, train_loss=0.533]Epoch 0:   1%|          | 100/19138 [11:17<35:48:59,  6.77s/it, loss=0.574, v_num=1, val_loss=0.803, train_loss=0.630]Epoch 0:   1%|          | 150/19138 [24:17<51:14:45,  9.72s/it, loss=0.574, v_num=1, val_loss=0.803, train_loss=0.630]Epoch 0:   1%|          | 150/19138 [24:17<51:14:45,  9.72s/it, loss=0.541, v_num=1, val_loss=0.803, train_loss=0.568]Epoch 0:   1%|          | 200/19138 [29:30<46:34:31,  8.85s/it, loss=0.541, v_num=1, val_loss=0.803, train_loss=0.568]Epoch 0:   1%|          | 200/19138 [29:30<46:34:31,  8.85s/it, loss=0.541, v_num=1, val_loss=0.803, train_loss=0.444]Epoch 0:   1%|▏         | 250/19138 [34:43<43:44:08,  8.34s/it, loss=0.541, v_num=1, val_loss=0.803, train_loss=0.444]Epoch 0:   1%|▏         | 250/19138 [34:43<43:44:09,  8.34s/it, loss=0.515, v_num=1, val_loss=0.803, train_loss=0.566]Epoch 0:   2%|▏         | 300/19138 [39:57<41:49:10,  7.99s/it, loss=0.515, v_num=1, val_loss=0.803, train_loss=0.566]Epoch 0:   2%|▏         | 300/19138 [39:57<41:49:10,  7.99s/it, loss=0.511, v_num=1, val_loss=0.803, train_loss=0.507]Epoch 0:   2%|▏         | 350/19138 [45:10<40:24:56,  7.74s/it, loss=0.511, v_num=1, val_loss=0.803, train_loss=0.507]Epoch 0:   2%|▏         | 350/19138 [45:10<40:24:56,  7.74s/it, loss=0.492, v_num=1, val_loss=0.803, train_loss=0.428]Epoch 0:   2%|▏         | 400/19138 [50:24<39:21:16,  7.56s/it, loss=0.492, v_num=1, val_loss=0.803, train_loss=0.428]Epoch 0:   2%|▏         | 400/19138 [50:24<39:21:17,  7.56s/it, loss=0.484, v_num=1, val_loss=0.803, train_loss=0.515]Epoch 0:   2%|▏         | 450/19138 [55:38<38:30:58,  7.42s/it, loss=0.484, v_num=1, val_loss=0.803, train_loss=0.515]Epoch 0:   2%|▏         | 450/19138 [55:38<38:30:58,  7.42s/it, loss=0.473, v_num=1, val_loss=0.803, train_loss=0.509]Epoch 0:   3%|▎         | 500/19138 [1:00:54<37:50:07,  7.31s/it, loss=0.473, v_num=1, val_loss=0.803, train_loss=0.509]Epoch 0:   3%|▎         | 500/19138 [1:00:54<37:50:07,  7.31s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]Epoch 0:   3%|▎         | 550/19138 [1:05:43<37:01:00,  7.17s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/1367 [00:00<?, ?it/s][A
Validating:   4%|▎         | 50/1367 [04:29<1:58:15,  5.39s/it][AEpoch 0:   3%|▎         | 600/19138 [1:10:12<36:09:10,  7.02s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:   7%|▋         | 100/1367 [08:45<1:50:32,  5.23s/it][AEpoch 0:   3%|▎         | 650/19138 [1:14:28<35:18:26,  6.88s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  11%|█         | 150/1367 [13:01<1:44:58,  5.18s/it][AEpoch 0:   4%|▎         | 700/19138 [1:18:44<34:33:51,  6.75s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  15%|█▍        | 200/1367 [17:16<1:40:14,  5.15s/it][AEpoch 0:   4%|▍         | 750/19138 [1:23:00<33:54:57,  6.64s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  18%|█▊        | 250/1367 [21:32<1:35:36,  5.14s/it][AEpoch 0:   4%|▍         | 800/19138 [1:27:15<33:20:04,  6.54s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  22%|██▏       | 300/1367 [25:47<1:31:06,  5.12s/it][AEpoch 0:   4%|▍         | 850/19138 [1:31:30<32:48:44,  6.46s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  26%|██▌       | 350/1367 [30:01<1:26:40,  5.11s/it][AEpoch 0:   5%|▍         | 900/19138 [1:35:44<32:20:15,  6.38s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  29%|██▉       | 400/1367 [34:16<1:22:19,  5.11s/it][AEpoch 0:   5%|▍         | 950/19138 [1:39:59<31:54:27,  6.32s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  33%|███▎      | 450/1367 [38:30<1:17:52,  5.10s/it][AEpoch 0:   5%|▌         | 1000/19138 [1:44:13<31:30:19,  6.25s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  37%|███▋      | 500/1367 [42:43<1:13:32,  5.09s/it][AEpoch 0:   5%|▌         | 1050/19138 [1:48:26<31:08:11,  6.20s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  40%|████      | 550/1367 [46:59<1:09:22,  5.09s/it][AEpoch 0:   6%|▌         | 1100/19138 [1:52:42<30:48:08,  6.15s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  44%|████▍     | 600/1367 [51:14<1:05:08,  5.10s/it][AEpoch 0:   6%|▌         | 1150/19138 [1:56:57<30:29:20,  6.10s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  48%|████▊     | 650/1367 [55:28<1:00:52,  5.09s/it][AEpoch 0:   6%|▋         | 1200/19138 [2:01:11<30:11:39,  6.06s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  51%|█████     | 700/1367 [59:42<56:35,  5.09s/it]  [AEpoch 0:   7%|▋         | 1250/19138 [2:05:25<29:54:57,  6.02s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  55%|█████▍    | 750/1367 [1:03:58<52:24,  5.10s/it][AEpoch 0:   7%|▋         | 1300/19138 [2:09:41<29:39:30,  5.99s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  59%|█████▊    | 800/1367 [1:08:13<48:11,  5.10s/it][AEpoch 0:   7%|▋         | 1350/19138 [2:13:56<29:24:54,  5.95s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  62%|██████▏   | 850/1367 [1:12:28<43:57,  5.10s/it][AEpoch 0:   7%|▋         | 1400/19138 [2:18:11<29:10:58,  5.92s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  66%|██████▌   | 900/1367 [1:16:42<39:39,  5.10s/it][AEpoch 0:   8%|▊         | 1450/19138 [2:22:26<28:57:29,  5.89s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  69%|██████▉   | 950/1367 [1:20:56<35:22,  5.09s/it][AEpoch 0:   8%|▊         | 1500/19138 [2:26:39<28:44:34,  5.87s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  73%|███████▎  | 1000/1367 [1:25:10<31:06,  5.09s/it][AEpoch 0:   8%|▊         | 1550/19138 [2:30:53<28:32:12,  5.84s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  77%|███████▋  | 1050/1367 [1:29:25<26:53,  5.09s/it][AEpoch 0:   8%|▊         | 1600/19138 [2:35:08<28:20:33,  5.82s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  80%|████████  | 1100/1367 [1:33:39<22:38,  5.09s/it][AEpoch 0:   9%|▊         | 1650/19138 [2:39:22<28:09:11,  5.80s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  84%|████████▍ | 1150/1367 [1:37:53<18:23,  5.09s/it][AEpoch 0:   9%|▉         | 1700/19138 [2:43:36<27:58:17,  5.77s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  88%|████████▊ | 1200/1367 [1:42:07<14:08,  5.08s/it][AEpoch 0:   9%|▉         | 1750/19138 [2:47:50<27:47:39,  5.75s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  91%|█████████▏| 1250/1367 [1:46:20<09:53,  5.07s/it][AEpoch 0:   9%|▉         | 1800/19138 [2:52:03<27:37:15,  5.74s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  95%|█████████▌| 1300/1367 [1:50:34<05:40,  5.08s/it][AEpoch 0:  10%|▉         | 1850/19138 [2:56:17<27:27:25,  5.72s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating:  99%|█████████▉| 1350/1367 [1:54:48<01:26,  5.08s/it][AEpoch 0:  10%|▉         | 1900/19138 [3:00:31<27:17:46,  5.70s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]
Validating: 100%|██████████| 1367/1367 [1:56:14<00:00,  5.08s/it][AEpoch 0:  10%|█         | 1950/19138 [3:01:57<26:43:55,  5.60s/it, loss=0.471, v_num=1, val_loss=0.803, train_loss=0.487]Epoch 0:  10%|█         | 1950/19138 [3:01:59<26:44:09,  5.60s/it, loss=0.499, v_num=1, val_loss=0.550, train_loss=0.489]
                                                                 [AEpoch 0:  10%|█         | 2000/19138 [3:02:27<26:03:31,  5.47s/it, loss=0.499, v_num=1, val_loss=0.550, train_loss=0.489]Epoch 0:  10%|█         | 2000/19138 [3:02:27<26:03:31,  5.47s/it, loss=0.508, v_num=1, val_loss=0.550, train_loss=0.488]Epoch 0:  11%|█         | 2050/19138 [3:07:40<26:04:27,  5.49s/it, loss=0.508, v_num=1, val_loss=0.550, train_loss=0.488]Epoch 0:  11%|█         | 2050/19138 [3:07:40<26:04:27,  5.49s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]  Epoch 0:  11%|█         | 2100/19138 [3:12:53<26:05:03,  5.51s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  11%|█         | 2100/19138 [3:12:53<26:05:03,  5.51s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  11%|█         | 2150/19138 [3:18:07<26:05:27,  5.53s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  11%|█         | 2150/19138 [3:18:07<26:05:27,  5.53s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  11%|█▏        | 2200/19138 [3:23:21<26:05:36,  5.55s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  11%|█▏        | 2200/19138 [3:23:21<26:05:36,  5.55s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  12%|█▏        | 2250/19138 [3:28:34<26:05:28,  5.56s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  12%|█▏        | 2250/19138 [3:28:34<26:05:28,  5.56s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  12%|█▏        | 2300/19138 [3:33:46<26:05:00,  5.58s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  12%|█▏        | 2300/19138 [3:33:46<26:05:00,  5.58s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  12%|█▏        | 2350/19138 [3:38:58<26:04:22,  5.59s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  12%|█▏        | 2350/19138 [3:38:58<26:04:22,  5.59s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  13%|█▎        | 2400/19138 [3:44:11<26:03:33,  5.60s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  13%|█▎        | 2400/19138 [3:44:11<26:03:33,  5.60s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  13%|█▎        | 2450/19138 [3:49:24<26:02:34,  5.62s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  13%|█▎        | 2450/19138 [3:49:24<26:02:34,  5.62s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  13%|█▎        | 2500/19138 [3:54:37<26:01:31,  5.63s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  13%|█▎        | 2500/19138 [3:54:37<26:01:31,  5.63s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]Epoch 0:  13%|█▎        | 2550/19138 [3:58:59<25:54:42,  5.62s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
/home/hd/hd_hd/hd_uu312/miniconda3/envs/CUNet/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:610: LightningDeprecationWarning: Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2 and will be removed in v1.4. Please, create your own `mc = ModelCheckpoint(monitor='your_monitor')` and use it as `Trainer(callbacks=[mc])`.
  warning_cache.deprecation(
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/1367 [00:00<?, ?it/s][A
Validating:   4%|▎         | 50/1367 [04:31<1:59:10,  5.43s/it][AEpoch 0:  14%|█▎        | 2600/19138 [4:03:31<25:48:59,  5.62s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:   7%|▋         | 100/1367 [08:45<1:50:23,  5.23s/it][AEpoch 0:  14%|█▍        | 2650/19138 [4:07:45<25:41:32,  5.61s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  11%|█         | 150/1367 [13:00<1:44:51,  5.17s/it][AEpoch 0:  14%|█▍        | 2700/19138 [4:12:00<25:34:17,  5.60s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  15%|█▍        | 200/1367 [17:16<1:40:07,  5.15s/it][AEpoch 0:  14%|█▍        | 2750/19138 [4:16:16<25:27:12,  5.59s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  18%|█▊        | 250/1367 [21:30<1:35:23,  5.12s/it][AEpoch 0:  15%|█▍        | 2800/19138 [4:20:30<25:20:04,  5.58s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  22%|██▏       | 300/1367 [25:44<1:30:51,  5.11s/it][AEpoch 0:  15%|█▍        | 2850/19138 [4:24:44<25:13:01,  5.57s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  26%|██▌       | 350/1367 [29:59<1:26:29,  5.10s/it][AEpoch 0:  15%|█▌        | 2900/19138 [4:28:59<25:06:08,  5.57s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  29%|██▉       | 400/1367 [34:13<1:22:11,  5.10s/it][AEpoch 0:  15%|█▌        | 2950/19138 [4:33:13<24:59:20,  5.56s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  33%|███▎      | 450/1367 [38:29<1:18:00,  5.10s/it][AEpoch 0:  16%|█▌        | 3000/19138 [4:37:29<24:52:42,  5.55s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  37%|███▋      | 500/1367 [42:44<1:13:46,  5.11s/it][AEpoch 0:  16%|█▌        | 3050/19138 [4:41:44<24:46:09,  5.54s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  40%|████      | 550/1367 [46:59<1:09:27,  5.10s/it][AEpoch 0:  16%|█▌        | 3100/19138 [4:45:59<24:39:35,  5.54s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  44%|████▍     | 600/1367 [51:13<1:05:08,  5.10s/it][AEpoch 0:  16%|█▋        | 3150/19138 [4:50:13<24:33:03,  5.53s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  48%|████▊     | 650/1367 [55:27<1:00:47,  5.09s/it][AEpoch 0:  17%|█▋        | 3200/19138 [4:54:26<24:26:32,  5.52s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  51%|█████     | 700/1367 [59:42<56:38,  5.09s/it]  [AEpoch 0:  17%|█▋        | 3250/19138 [4:58:42<24:20:16,  5.51s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  55%|█████▍    | 750/1367 [1:03:56<52:19,  5.09s/it][AEpoch 0:  17%|█▋        | 3300/19138 [5:02:56<24:13:55,  5.51s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  59%|█████▊    | 800/1367 [1:08:10<48:04,  5.09s/it][AEpoch 0:  18%|█▊        | 3350/19138 [5:07:10<24:07:40,  5.50s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  62%|██████▏   | 850/1367 [1:12:24<43:48,  5.08s/it][AEpoch 0:  18%|█▊        | 3400/19138 [5:11:24<24:01:27,  5.50s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  66%|██████▌   | 900/1367 [1:16:56<40:22,  5.19s/it][AEpoch 0:  18%|█▊        | 3450/19138 [5:15:55<23:56:37,  5.49s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  69%|██████▉   | 950/1367 [1:21:10<35:50,  5.16s/it][AEpoch 0:  18%|█▊        | 3500/19138 [5:20:10<23:50:30,  5.49s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  73%|███████▎  | 1000/1367 [1:25:25<31:26,  5.14s/it][AEpoch 0:  19%|█▊        | 3550/19138 [5:24:25<23:44:30,  5.48s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  77%|███████▋  | 1050/1367 [1:29:39<27:04,  5.12s/it][AEpoch 0:  19%|█▉        | 3600/19138 [5:28:39<23:38:32,  5.48s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  80%|████████  | 1100/1367 [1:33:53<22:43,  5.11s/it][AEpoch 0:  19%|█▉        | 3650/19138 [5:32:53<23:32:31,  5.47s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
Validating:  84%|████████▍ | 1150/1367 [1:38:06<18:26,  5.10s/it][AEpoch 0:  19%|█▉        | 3700/19138 [5:37:06<23:26:34,  5.47s/it, loss=nan, v_num=1, val_loss=0.550, train_loss=nan.0]
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 8795437.1 ON o03c04 CANCELLED AT 2025-06-05T08:42:35 ***
slurmstepd: error: *** JOB 8795437 ON o03c04 CANCELLED AT 2025-06-05T08:42:35 ***
